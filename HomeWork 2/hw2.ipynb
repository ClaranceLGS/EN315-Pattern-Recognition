{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Homework 02</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       species  class_encoded\n",
      "0       Adelie              0\n",
      "1       Adelie              0\n",
      "2       Adelie              0\n",
      "4       Adelie              0\n",
      "5       Adelie              0\n",
      "..         ...            ...\n",
      "215  Chinstrap              1\n",
      "216  Chinstrap              1\n",
      "217  Chinstrap              1\n",
      "218  Chinstrap              1\n",
      "219  Chinstrap              1\n",
      "\n",
      "[214 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the penguins dataset\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "# print(df.head())\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Filter rows for 'Adelie' and 'Chinstrap' classes\n",
    "selected_classes = ['Adelie', 'Chinstrap']\n",
    "df_filtered = df[df['species'].isin(selected_classes)].copy()  # Make a copy to avoid the warning\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the species column\n",
    "y_encoded = le.fit_transform(df_filtered['species'])\n",
    "\n",
    "df_filtered['class_encoded'] = y_encoded\n",
    "# print(df_filtered.head())\n",
    "\n",
    "# Display the filtered and encoded DataFrame\n",
    "print(df_filtered[['species', 'class_encoded']])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "y = df_filtered['class_encoded']  # Target variable\n",
    "X = df_filtered.drop(['species', 'island', 'sex','class_encoded'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the purpose of \"y_encoded = le.fit_transform(df_filtered['species'])\" ?\n",
    "- To encode the categorical target variable ('species' column in the \"df_filtered\" dataframe) into numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the purpose of \"X = df.drop(['species', 'island', 'sex'], axis=1)\" ?\n",
    "- To remove certain columns ('species', 'island', 'sex') from the dataframe \"df\" and create a feature matrix 'X'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why we cannot use \"island\" and \"sex\" features?\n",
    "- Because they are categorical features and we need to encode them into numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5813953488372093\n",
      "[[ 2.76031248e-03 -8.38966923e-05  4.61499704e-04 -2.86532980e-04]] [-8.53929629e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model. Here we are using saga solver to learn weights.\n",
    "logreg = LogisticRegression(solver='saga')\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(logreg.coef_, logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAIjCAYAAAAZajMiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABH7UlEQVR4nO3deVhV5f7//9dGYIMoIA4ghYBKiuaUJge11CTn6aupdMjM49BxTO1YecqxU5aZmoZafkobNLOOWsfKWbOBTFErTU0LhzSwVEBMEeH+/dHPfbUFFBDZsHo+rmtduu91r7Xe62a5fbm899o2Y4wRAAAAYAFuri4AAAAAKC6EWwAAAFgG4RYAAACWQbgFAACAZRBuAQAAYBmEWwAAAFgG4RYAAACWQbgFAACAZRBuAQAAYBmEW6AMCwsL00MPPeTqMm7YlClTZLPZSuRYbdq0UZs2bRyvt27dKpvNpvfff79Ejv/QQw8pLCysRI5VVBkZGRo8eLCCgoJks9k0ZswYV5f0l2Gz2TRlypRCb7dkyRLZbDbt3Lnzun2v/jMAWA3hFiiFfvzxRz388MOqWbOmvLy85Ovrq5YtW+qll17ShQsXXF3eNV35S/bK4uXlpeDgYHXo0EFz587VuXPniuU4J0+e1JQpU7Rnz55i2V9xKs21FcSzzz6rJUuWaNiwYXrrrbfUv3//XH2u/IPkektpDFHPPvusVq9efd1+s2bNks1m08aNG/Pts2jRItlsNn344YfFWCGAG+Hu6gIAOPvoo4/Up08f2e12Pfjgg7r99tt16dIlff755xo/frz27dunV1991dVlXte0adMUHh6urKwsJScna+vWrRozZoxmzZqlDz/8UA0bNnT0feqpp/TEE08Uav8nT57U1KlTFRYWpsaNGxd4u/Xr1xfqOEVxrdoWLVqknJycm17Djdi8ebP+9re/afLkyfn26dWrl2rXru14nZGRoWHDhun//b//p169ejnaAwMDb2qtRfHss8/qvvvuU8+ePa/ZLzY2VuPHj9eyZcsUExOTZ59ly5apcuXK6tSpU7HUduHCBbm781czcCP4EwSUIklJSYqNjVVoaKg2b96s6tWrO9aNGDFChw8f1kcffeTCCguuU6dOatasmeP1hAkTtHnzZnXt2lXdu3fX/v375e3tLUlyd3e/6X+h//777ypfvrw8PT1v6nGux8PDw6XHL4hTp06pXr161+zTsGFDp3+g/Pbbbxo2bJgaNmyoBx544IZrOH/+vHx8fG54PzciODhYbdu21cqVK7VgwQLZ7Xan9SdOnNC2bds0dOjQG/q55uTk6NKlS/Ly8pKXl9eNlg385TEtAShFZsyYoYyMDL322mtOwfaK2rVr65FHHsl3+zNnzuhf//qXGjRooAoVKsjX11edOnXSN998k6vvvHnzVL9+fZUvX16VKlVSs2bNtGzZMsf6c+fOacyYMQoLC5Pdble1atV07733ateuXUU+v3vuuUcTJ07U0aNH9fbbbzva85pzu2HDBrVq1Ur+/v6qUKGC6tSpo3//+9+S/pgne+edd0qSBg4c6Pgv8CVLlkj6Y07h7bffrsTERN19990qX768Y9v85htmZ2fr3//+t4KCguTj46Pu3bvr+PHjTn3ym+P8531er7a85tyeP39ejz76qEJCQmS321WnTh3NnDlTxhinfjabTSNHjtTq1at1++23y263q379+lq7dm3eA36VU6dOadCgQQoMDJSXl5caNWqkN954w7H+yvzjpKQkffTRR47ajxw5UqD9X+3o0aMaPny46tSpI29vb1WuXFl9+vTJtb8rU1k+/fRTDR8+XNWqVdOtt97qWB8fH6+aNWvK29tbzZs312effZbnzzEzM1OTJ09W7dq1ZbfbFRISoscee0yZmZmOPjabTefPn9cbb7zhOL9rzVt/4IEHlJaWluc/KpcvX66cnBzFxcVJkmbOnKkWLVqocuXK8vb2VtOmTfOcy33l57h06VLVr19fdrvd8TO8es5tQcfwit9//10PP/ywKleuLF9fXz344IM6e/ZsvudXmLEDygru3AKlyP/+9z/VrFlTLVq0KNL2P/30k1avXq0+ffooPDxcKSkpeuWVV9S6dWt9//33Cg4OlvTHf42PHj1a9913nx555BFdvHhR3377rbZv366///3vkqR//vOfev/99zVy5EjVq1dPp0+f1ueff679+/frjjvuKPI59u/fX//+97+1fv16DRkyJM8++/btU9euXdWwYUNNmzZNdrtdhw8f1hdffCFJioyM1LRp0zRp0iQNHTpUd911lyQ5jdvp06fVqVMnxcbG6oEHHrjuf48/88wzstlsevzxx3Xq1CnNmTNHMTEx2rNnj+MOc0EUpLY/M8aoe/fu2rJliwYNGqTGjRtr3bp1Gj9+vE6cOKHZs2c79f/888+1cuVKDR8+XBUrVtTcuXPVu3dvHTt2TJUrV863rgsXLqhNmzY6fPiwRo4cqfDwcL333nt66KGHlJqaqkceeUSRkZF66623NHbsWN1666169NFHJUlVq1Yt8Pn/2Y4dO/Tll18qNjZWt956q44cOaIFCxaoTZs2+v7771W+fHmn/sOHD1fVqlU1adIknT9/XpK0YMECjRw5UnfddZfGjh2rI0eOqGfPnqpUqZJTAM7JyVH37t31+eefa+jQoYqMjNR3332n2bNn64cffnDMsX3rrbc0ePBgNW/eXEOHDpUk1apVK99z6NWrl4YNG6Zly5Y5TbeQ/piSEBoaqpYtW0qSXnrpJXXv3l1xcXG6dOmSli9frj59+mjNmjXq0qWL07abN2/WihUrNHLkSFWpUiXfDxkWdgxHjhwpf39/TZkyRQcPHtSCBQt09OhRxz9c8lLQsQPKDAOgVEhLSzOSTI8ePQq8TWhoqBkwYIDj9cWLF012drZTn6SkJGO32820adMcbT169DD169e/5r79/PzMiBEjClzLFYsXLzaSzI4dO6657yZNmjheT5482fz57Wj27NlGkvn111/z3ceOHTuMJLN48eJc61q3bm0kmYULF+a5rnXr1o7XW7ZsMZLMLbfcYtLT0x3tK1asMJLMSy+95Gi7erzz2+e1ahswYIAJDQ11vF69erWRZP7zn/849bvvvvuMzWYzhw8fdrRJMp6enk5t33zzjZFk5s2bl+tYfzZnzhwjybz99tuOtkuXLpno6GhToUIFp3MPDQ01Xbp0ueb+rvbrr78aSWby5MmOtt9//z1Xv4SEBCPJvPnmm462K9dMq1atzOXLlx3tmZmZpnLlyubOO+80WVlZjvYlS5YYSU5j/tZbbxk3Nzfz2WefOR1v4cKFRpL54osvHG0+Pj55/hzz06dPH+Pl5WXS0tIcbQcOHDCSzIQJE/I930uXLpnbb7/d3HPPPU7tkoybm5vZt29frmPd6Bg2bdrUXLp0ydE+Y8YMI8l88MEHjrarr9fCjB1QFjAtASgl0tPTJUkVK1Ys8j7sdrvc3P74Y52dna3Tp087/kv/z9MJ/P399fPPP2vHjh357svf31/bt2/XyZMni1xPfipUqHDNpyb4+/tLkj744IMif/jKbrdr4MCBBe7/4IMPOo39fffdp+rVq+vjjz8u0vEL6uOPP1a5cuU0evRop/ZHH31Uxhh98sknTu0xMTFOdxobNmwoX19f/fTTT9c9TlBQkO6//35Hm4eHh0aPHq2MjAx9+umnxXA2zv58xzsrK0unT59W7dq15e/vn+f0liFDhqhcuXKO1zt37tTp06c1ZMgQpznZcXFxqlSpktO27733niIjI1W3bl399ttvjuWee+6RJG3ZsqXI5/HAAw/o4sWLWrlypaPtyhSeK1MSrj7fs2fPKi0tTXfddVee59q6devrzmu+ep8FGcOr5/8OGzZM7u7u17yOb+bYAa5AuAVKCV9fX0m6oUdl5eTkaPbs2YqIiJDdbleVKlVUtWpVffvtt0pLS3P0e/zxx1WhQgU1b95cERERGjFihOO//K+YMWOG9u7dq5CQEDVv3lxTpky5boAqqIyMjGuG+H79+qlly5YaPHiwAgMDFRsbqxUrVhQq6N5yyy2F+vBYRESE02ubzabatWsXeb5pQR09elTBwcG5xiMyMtKx/s9q1KiRax+VKlW67rzKo0ePKiIiwvGPn+sdpzhcuHBBkyZNcswlvnI9pqamOl2PV4SHh+eqWZLTUxmkPz6AePV/4x86dEj79u1T1apVnZbbbrtN0h/zjYuqU6dOCggIcJqT/s4776hRo0aqX7++o23NmjX629/+Ji8vLwUEBKhq1apasGBBgc41P4Udw6uv4woVKqh69erXvI5v5tgBrsCcW6CU8PX1VXBwsPbu3VvkfTz77LOaOHGi/vGPf+jpp59WQECA3NzcNGbMGKdgGBkZqYMHD2rNmjVau3at/vvf/2r+/PmaNGmSpk6dKknq27ev7rrrLq1atUrr16/XCy+8oOeff14rV668occe/fzzz0pLS8sVWP7M29tb27Zt05YtW/TRRx9p7dq1evfdd3XPPfdo/fr1Tnf3rrWP4pbfnMXs7OwC1VQc8juOuerDZ6XBqFGjtHjxYo0ZM0bR0dHy8/OTzWZTbGxsnv9QuZGfWU5Ojho0aKBZs2bluT4kJKTI+/bw8FDfvn21aNEipaSk6NixYzp06JBmzJjh6PPZZ5+pe/fuuvvuuzV//nxVr15dHh4eWrx4sVMovqKg51rYMSyKmzl2gCsQboFSpGvXrnr11VeVkJCg6OjoQm///vvvq23btnrttdec2lNTU1WlShWnNh8fH/Xr10/9+vXTpUuX1KtXLz3zzDOaMGGC43FE1atX1/DhwzV8+HCdOnVKd9xxh5555pkbCrdvvfWWJKlDhw7X7Ofm5qZ27dqpXbt2mjVrlp599lk9+eST2rJli2JiYor9G80OHTrk9NoYo8OHDzs97qpSpUpKTU3Nte3Ro0dVs2ZNx+vC1BYaGqqNGzfq3LlzTndvDxw44FhfHEJDQ/Xtt98qJyfH6e5tcR/nz95//30NGDBAL774oqPt4sWLeY5hXq7UdPjwYbVt29bRfvnyZR05csTpZ1OrVi198803ateu3XXHvyjXTlxcnBYuXKh3331XSUlJstlsTlM8/vvf/8rLy0vr1q1zemTY4sWLC32sPyvsGB46dMhprDIyMvTLL7+oc+fO+R6jMGMHlAVMSwBKkccee0w+Pj4aPHiwUlJScq3/8ccf9dJLL+W7fbly5XLdwXvvvfd04sQJp7bTp087vfb09FS9evVkjFFWVpays7Nz/ZdntWrVFBwcfEOPBtq8ebOefvpphYeHO81VvNqZM2dytV35MoQrx7/yDNSCBqXrefPNN52mhLz//vv65ZdfnIJ8rVq19NVXX+nSpUuOtjVr1uR6ZFhhauvcubOys7P18ssvO7XPnj1bNput2L4coHPnzkpOTta7777raLt8+bLmzZunChUqqHXr1sVynD/L63qcN2+esrOzC7R9s2bNVLlyZS1atEiXL192tC9dujTXNIy+ffvqxIkTWrRoUa79XLhwwfH0BemPn09hr5uWLVsqLCxMb7/9tt599121bt3a6WkN5cqVk81mczq3I0eO3PCTBgo7hq+++qqysrIcrxcsWKDLly9f8zoqzNgBZQF3boFSpFatWlq2bJn69eunyMhIp28o+/LLLx2PbspP165dNW3aNA0cOFAtWrTQd999p6VLlzrdVZSk9u3bKygoSC1btlRgYKD279+vl19+WV26dFHFihWVmpqqW2+9Vffdd58aNWqkChUqaOPGjdqxY4fTHaRr+eSTT3TgwAFdvnxZKSkp2rx5szZs2KDQ0FB9+OGH13xY/bRp07Rt2zZ16dJFoaGhOnXqlObPn69bb71VrVq1coyVv7+/Fi5cqIoVK8rHx0dRUVEFnst4tYCAALVq1UoDBw5USkqK5syZo9q1azs9rmzw4MF6//331bFjR/Xt21c//vij3n777VyPkipMbd26dVPbtm315JNP6siRI2rUqJHWr1+vDz74QGPGjLnmY6oKY+jQoXrllVf00EMPKTExUWFhYXr//ff1xRdfaM6cOTf0Qcb8dO3aVW+99Zb8/PxUr149JSQkaOPGjdd8ZNmfeXp6asqUKRo1apTuuece9e3bV0eOHNGSJUtUq1Ytp7uM/fv314oVK/TPf/5TW7ZsUcuWLZWdna0DBw5oxYoVWrduneNLRZo2baqNGzdq1qxZCg4OVnh4uKKioq5Zi81m09///nc9++yzkv64Rv+sS5cumjVrljp27Ki///3vOnXqlOLj41W7dm19++23hRk2J4Udw0uXLqldu3bq27evDh48qPnz56tVq1bq3r17vscozNgBZYILn9QAIB8//PCDGTJkiAkLCzOenp6mYsWKpmXLlmbevHnm4sWLjn55PQrs0UcfNdWrVzfe3t6mZcuWJiEhIdejf1555RVz9913m8qVKxu73W5q1aplxo8f73jUUWZmphk/frxp1KiRqVixovHx8TGNGjUy8+fPv27tVx5JdGXx9PQ0QUFB5t577zUvvfSS0yOnrrj6UWCbNm0yPXr0MMHBwcbT09MEBweb+++/3/zwww9O233wwQemXr16xt3d3enRW61bt873UWf5PQrsnXfeMRMmTDDVqlUz3t7epkuXLubo0aO5tn/xxRfNLbfcYux2u2nZsqXZuXNnrn1eq7arHwVmjDHnzp0zY8eONcHBwcbDw8NERESYF154weTk5Dj1k5Tn49nye0TZ1VJSUszAgQNNlSpVjKenp2nQoEGejysrrkeBnT171nG8ChUqmA4dOpgDBw7kqvd6j4+bO3euCQ0NNXa73TRv3tx88cUXpmnTpqZjx45O/S5dumSef/55U79+fWO3202lSpVM06ZNzdSpU3M9xuvuu+823t7eRlKBHwu2b98+I8nY7XZz9uzZXOtfe+01ExERYex2u6lbt65ZvHhxrmvbmPx/jlfW3cgYfvrpp2bo0KGmUqVKpkKFCiYuLs6cPn3a6Rh5Xa8FHTugLLAZUwo/hQAAQD5ycnJUtWpV9erVK8//Sgfw18acWwBAqXXx4sVcc07ffPNNnTlzJs+vUQYA7twCAEqtrVu3auzYserTp48qV66sXbt26bXXXlNkZKQSExML9SxjAH8NfKAMAFBqhYWFKSQkRHPnztWZM2cUEBCgBx98UM899xzBFkCeuHMLAAAAy2DOLQAAACyDcAsAAADLYM6t/niszMmTJ1WxYkW+ehAAAKAUMsbo3LlzCg4Odvoa8asRbiWdPHlSISEhri4DAAAA13H8+HGnr7++GuFWcnzt5PHjx+Xr6+viagAAAHC19PR0hYSEXPfrwgm3kmMqgq+vL+EWAACgFLveFFI+UAYAAADLINwCAADAMgi3AAAAsAzCLQAAACyDcAsAAADLINwCAADAMgi3AAAAsAzCLQAAACyDcAsAAADLINwCAADAMgi3AAAAsAzCLQAAACyDcAsAAADLINwCAADAMgi3AAAAsAzCLQAAACyDcAsAAADLINwCAADAMgi3AAAAsAx3VxfwVxX2xEeuLgHATXbkuS6uLgEA/nK4cwsAAADLINwCAADAMgi3AAAAsAzCLQAAACyDcAsAAADLINwCAADAMgi3AAAAsAzCLQAAACyDcAsAAADLINwCAADAMgi3AAAAsAzCLQAAACyDcAsAAADLcGm43bZtm7p166bg4GDZbDatXr06377//Oc/ZbPZNGfOHKf2M2fOKC4uTr6+vvL399egQYOUkZFxcwsHAABAqeTScHv+/Hk1atRI8fHx1+y3atUqffXVVwoODs61Li4uTvv27dOGDRu0Zs0abdu2TUOHDr1ZJQMAAKAUc3flwTt16qROnTpds8+JEyc0atQorVu3Tl26dHFat3//fq1du1Y7duxQs2bNJEnz5s1T586dNXPmzDzDMAAAAKyrVM+5zcnJUf/+/TV+/HjVr18/1/qEhAT5+/s7gq0kxcTEyM3NTdu3b893v5mZmUpPT3daAAAAUPaV6nD7/PPPy93dXaNHj85zfXJysqpVq+bU5u7uroCAACUnJ+e73+nTp8vPz8+xhISEFGvdAAAAcI1SG24TExP10ksvacmSJbLZbMW67wkTJigtLc2xHD9+vFj3DwAAANcoteH2s88+06lTp1SjRg25u7vL3d1dR48e1aOPPqqwsDBJUlBQkE6dOuW03eXLl3XmzBkFBQXlu2+73S5fX1+nBQAAAGWfSz9Qdi39+/dXTEyMU1uHDh3Uv39/DRw4UJIUHR2t1NRUJSYmqmnTppKkzZs3KycnR1FRUSVeMwAAAFzLpeE2IyNDhw8fdrxOSkrSnj17FBAQoBo1aqhy5cpO/T08PBQUFKQ6depIkiIjI9WxY0cNGTJECxcuVFZWlkaOHKnY2FielAAAAPAX5NJpCTt37lSTJk3UpEkTSdK4cePUpEkTTZo0qcD7WLp0qerWrat27dqpc+fOatWqlV599dWbVTIAAABKMZfeuW3Tpo2MMQXuf+TIkVxtAQEBWrZsWTFWBQAAgLKq1H6gDAAAACgswi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMl4bbbdu2qVu3bgoODpbNZtPq1asd67KysvT444+rQYMG8vHxUXBwsB588EGdPHnSaR9nzpxRXFycfH195e/vr0GDBikjI6OEzwQAAAClgUvD7fnz59WoUSPFx8fnWvf7779r165dmjhxonbt2qWVK1fq4MGD6t69u1O/uLg47du3Txs2bNCaNWu0bds2DR06tKROAQAAAKWIzRhjXF2EJNlsNq1atUo9e/bMt8+OHTvUvHlzHT16VDVq1ND+/ftVr1497dixQ82aNZMkrV27Vp07d9bPP/+s4ODgAh07PT1dfn5+SktLk6+vb3GcznWFPfFRiRwHgOscea6Lq0sAAMsoaF4rU3Nu09LSZLPZ5O/vL0lKSEiQv7+/I9hKUkxMjNzc3LR9+/Z895OZman09HSnBQAAAGVfmQm3Fy9e1OOPP67777/fkdaTk5NVrVo1p37u7u4KCAhQcnJyvvuaPn26/Pz8HEtISMhNrR0AAAAlo0yE26ysLPXt21fGGC1YsOCG9zdhwgSlpaU5luPHjxdDlQAAAHA1d1cXcD1Xgu3Ro0e1efNmpzkWQUFBOnXqlFP/y5cv68yZMwoKCsp3n3a7XXa7/abVDAAAANco1XdurwTbQ4cOaePGjapcubLT+ujoaKWmpioxMdHRtnnzZuXk5CgqKqqkywUAAICLufTObUZGhg4fPux4nZSUpD179iggIEDVq1fXfffdp127dmnNmjXKzs52zKMNCAiQp6enIiMj1bFjRw0ZMkQLFy5UVlaWRo4cqdjY2AI/KQEAAADW4dJwu3PnTrVt29bxety4cZKkAQMGaMqUKfrwww8lSY0bN3babsuWLWrTpo0kaenSpRo5cqTatWsnNzc39e7dW3Pnzi2R+gEAAFC6uDTctmnTRtd6zG5BHsEbEBCgZcuWFWdZAAAAKKNK9ZxbAAAAoDAItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDJcGm63bdumbt26KTg4WDabTatXr3Zab4zRpEmTVL16dXl7eysmJkaHDh1y6nPmzBnFxcXJ19dX/v7+GjRokDIyMkrwLAAAAFBauDTcnj9/Xo0aNVJ8fHye62fMmKG5c+dq4cKF2r59u3x8fNShQwddvHjR0ScuLk779u3Thg0btGbNGm3btk1Dhw4tqVMAAABAKeLuyoN36tRJnTp1ynOdMUZz5szRU089pR49ekiS3nzzTQUGBmr16tWKjY3V/v37tXbtWu3YsUPNmjWTJM2bN0+dO3fWzJkzFRwcXGLnAgAAANcrtXNuk5KSlJycrJiYGEebn5+foqKilJCQIElKSEiQv7+/I9hKUkxMjNzc3LR9+/Z8952Zman09HSnBQAAAGVfqQ23ycnJkqTAwECn9sDAQMe65ORkVatWzWm9u7u7AgICHH3yMn36dPn5+TmWkJCQYq4eAAAArlBqw+3NNGHCBKWlpTmW48ePu7okAAAAFINSG26DgoIkSSkpKU7tKSkpjnVBQUE6deqU0/rLly/rzJkzjj55sdvt8vX1dVoAAABQ9pXacBseHq6goCBt2rTJ0Zaenq7t27crOjpakhQdHa3U1FQlJiY6+mzevFk5OTmKiooq8ZoBAADgWi59WkJGRoYOHz7seJ2UlKQ9e/YoICBANWrU0JgxY/Sf//xHERERCg8P18SJExUcHKyePXtKkiIjI9WxY0cNGTJECxcuVFZWlkaOHKnY2FielAAAAPAX5NJwu3PnTrVt29bxety4cZKkAQMGaMmSJXrsscd0/vx5DR06VKmpqWrVqpXWrl0rLy8vxzZLly7VyJEj1a5dO7m5ual3796aO3duiZ8LAAAAXM9mjDGuLsLV0tPT5efnp7S0tBKbfxv2xEclchwArnPkuS6uLgEALKOgea3UzrkFAAAACotwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsg3AIAAMAyCLcAAACwDMItAAAALINwCwAAAMsoUritWbOmTp8+nas9NTVVNWvWvOGiAAAAgKIoUrg9cuSIsrOzc7VnZmbqxIkTN1wUAAAAUBTuhen84YcfOn6/bt06+fn5OV5nZ2dr06ZNCgsLK7biAAAAgMIoVLjt2bOnJMlms2nAgAFO6zw8PBQWFqYXX3yx2IoDAAAACqNQ0xJycnKUk5OjGjVq6NSpU47XOTk5yszM1MGDB9W1a9diKy47O1sTJ05UeHi4vL29VatWLT399NMyxjj6GGM0adIkVa9eXd7e3oqJidGhQ4eKrQYAAACUHUWac5uUlKQqVaoUdy25PP/881qwYIFefvll7d+/X88//7xmzJihefPmOfrMmDFDc+fO1cKFC7V9+3b5+PioQ4cOunjx4k2vDwAAAKVLoaYl/NmmTZu0adMmxx3cP3v99ddvuDBJ+vLLL9WjRw916dJFkhQWFqZ33nlHX3/9taQ/7trOmTNHTz31lHr06CFJevPNNxUYGKjVq1crNja2WOoAAABA2VCkO7dTp05V+/bttWnTJv322286e/as01JcWrRooU2bNumHH36QJH3zzTf6/PPP1alTJ0l/3EFOTk5WTEyMYxs/Pz9FRUUpISEh3/1mZmYqPT3daQEAAEDZV6Q7twsXLtSSJUvUv3//4q7HyRNPPKH09HTVrVtX5cqVU3Z2tp555hnFxcVJkpKTkyVJgYGBTtsFBgY61uVl+vTpmjp16s0rHAAAAC5RpDu3ly5dUosWLYq7llxWrFihpUuXatmyZdq1a5feeOMNzZw5U2+88cYN7XfChAlKS0tzLMePHy+migEAAOBKRQq3gwcP1rJly4q7llzGjx+vJ554QrGxsWrQoIH69++vsWPHavr06ZKkoKAgSVJKSorTdikpKY51ebHb7fL19XVaAAAAUPYVaVrCxYsX9eqrr2rjxo1q2LChPDw8nNbPmjWrWIr7/fff5ebmnL/LlSvn+ABbeHi4goKCtGnTJjVu3FiSlJ6eru3bt2vYsGHFUgMAAADKjiKF22+//dYRJvfu3eu0zmaz3XBRV3Tr1k3PPPOMatSoofr162v37t2aNWuW/vGPfziONWbMGP3nP/9RRESEwsPDNXHiRAUHBzu+cAIAAAB/HUUKt1u2bCnuOvI0b948TZw4UcOHD9epU6cUHByshx9+WJMmTXL0eeyxx3T+/HkNHTpUqampatWqldauXSsvL68SqREAAAClh838+eu+/qLS09Pl5+entLS0Ept/G/bERyVyHACuc+S5Lq4uAQAso6B5rUh3btu2bXvN6QebN28uym4BAACAG1KkcHtlvu0VWVlZ2rNnj/bu3asBAwYUR10AAABAoRUp3M6ePTvP9ilTpigjI+OGCgIAAACKqkjPuc3PAw88oNdff704dwkAAAAUWLGG24SEBJ5SAAAAAJcp0rSEXr16Ob02xuiXX37Rzp07NXHixGIpDAAAACisIoVbPz8/p9dubm6qU6eOpk2bpvbt2xdLYQAAAEBhFSncLl68uLjrAAAAAG5YkcLtFYmJidq/f78kqX79+mrSpEmxFAUAAAAURZHC7alTpxQbG6utW7fK399fkpSamqq2bdtq+fLlqlq1anHWCAAAABRIkZ6WMGrUKJ07d0779u3TmTNndObMGe3du1fp6ekaPXp0cdcIAAAAFEiR7tyuXbtWGzduVGRkpKOtXr16io+P5wNlAAAAcJki3bnNycmRh4dHrnYPDw/l5OTccFEAAABAURQp3N5zzz165JFHdPLkSUfbiRMnNHbsWLVr167YigMAAAAKo0jh9uWXX1Z6errCwsJUq1Yt1apVS+Hh4UpPT9e8efOKu0YAAACgQIo05zYkJES7du3Sxo0bdeDAAUlSZGSkYmJiirU4AAAAoDAKded28+bNqlevntLT02Wz2XTvvfdq1KhRGjVqlO68807Vr19fn3322c2qFQAAALimQoXbOXPmaMiQIfL19c21zs/PTw8//LBmzZpVbMUBAAAAhVGocPvNN9+oY8eO+a5v3769EhMTb7goAAAAoCgKFW5TUlLyfATYFe7u7vr1119vuCgAAACgKAoVbm+55Rbt3bs33/XffvutqlevfsNFAQAAAEVRqHDbuXNnTZw4URcvXsy17sKFC5o8ebK6du1abMUBAAAAhVGoR4E99dRTWrlypW677TaNHDlSderUkSQdOHBA8fHxys7O1pNPPnlTCgUAAACup1DhNjAwUF9++aWGDRumCRMmyBgjSbLZbOrQoYPi4+MVGBh4UwoFAAAArqfQX+IQGhqqjz/+WGfPntXhw4dljFFERIQqVap0M+oDAAAACqxI31AmSZUqVdKdd95ZnLUAAAAAN6RQHygDAAAASjPCLQAAACyDcAsAAADLKPKcWwAA8hP2xEeuLgHATXbkuS6uLiFP3LkFAACAZRBuAQAAYBmEWwAAAFgG4RYAAACWQbgFAACAZRBuAQAAYBmEWwAAAFgG4RYAAACWQbgFAACAZRBuAQAAYBmEWwAAAFgG4RYAAACWQbgFAACAZRBuAQAAYBmEWwAAAFgG4RYAAACWQbgFAACAZRBuAQAAYBmEWwAAAFhGqQ+3J06c0AMPPKDKlSvL29tbDRo00M6dOx3rjTGaNGmSqlevLm9vb8XExOjQoUMurBgAAACuUqrD7dmzZ9WyZUt5eHjok08+0ffff68XX3xRlSpVcvSZMWOG5s6dq4ULF2r79u3y8fFRhw4ddPHiRRdWDgAAAFdwd3UB1/L8888rJCREixcvdrSFh4c7fm+M0Zw5c/TUU0+pR48ekqQ333xTgYGBWr16tWJjY0u8ZgAAALhOqb5z++GHH6pZs2bq06ePqlWrpiZNmmjRokWO9UlJSUpOTlZMTIyjzc/PT1FRUUpISMh3v5mZmUpPT3daAAAAUPaV6nD7008/acGCBYqIiNC6des0bNgwjR49Wm+88YYkKTk5WZIUGBjotF1gYKBjXV6mT58uPz8/xxISEnLzTgIAAAAlplSH25ycHN1xxx169tln1aRJEw0dOlRDhgzRwoULb2i/EyZMUFpammM5fvx4MVUMAAAAVyrV4bZ69eqqV6+eU1tkZKSOHTsmSQoKCpIkpaSkOPVJSUlxrMuL3W6Xr6+v0wIAAICyr1SH25YtW+rgwYNObT/88INCQ0Ml/fHhsqCgIG3atMmxPj09Xdu3b1d0dHSJ1goAAADXK9VPSxg7dqxatGihZ599Vn379tXXX3+tV199Va+++qokyWazacyYMfrPf/6jiIgIhYeHa+LEiQoODlbPnj1dWzwAAABKXKkOt3feeadWrVqlCRMmaNq0aQoPD9ecOXMUFxfn6PPYY4/p/PnzGjp0qFJTU9WqVSutXbtWXl5eLqwcAAAArlCqw60kde3aVV27ds13vc1m07Rp0zRt2rQSrAoAAAClUamecwsAAAAUBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYRpkKt88995xsNpvGjBnjaLt48aJGjBihypUrq0KFCurdu7dSUlJcVyQAAABcpsyE2x07duiVV15Rw4YNndrHjh2r//3vf3rvvff06aef6uTJk+rVq5eLqgQAAIArlYlwm5GRobi4OC1atEiVKlVytKelpem1117TrFmzdM8996hp06ZavHixvvzyS3311VcurBgAAACuUCbC7YgRI9SlSxfFxMQ4tScmJiorK8upvW7duqpRo4YSEhLy3V9mZqbS09OdFgAAAJR97q4u4HqWL1+uXbt2aceOHbnWJScny9PTU/7+/k7tgYGBSk5Oznef06dP19SpU4u7VAAAALhYqb5ze/z4cT3yyCNaunSpvLy8im2/EyZMUFpammM5fvx4se0bAAAArlOqw21iYqJOnTqlO+64Q+7u7nJ3d9enn36quXPnyt3dXYGBgbp06ZJSU1OdtktJSVFQUFC++7Xb7fL19XVaAAAAUPaV6mkJ7dq103fffefUNnDgQNWtW1ePP/64QkJC5OHhoU2bNql3796SpIMHD+rYsWOKjo52RckAAABwoVIdbitWrKjbb7/dqc3Hx0eVK1d2tA8aNEjjxo1TQECAfH19NWrUKEVHR+tvf/ubK0oGAACAC5XqcFsQs2fPlpubm3r37q3MzEx16NBB8+fPd3VZAAAAcIEyF263bt3q9NrLy0vx8fGKj493TUEAAAAoNUr1B8oAAACAwiDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDJKdbidPn267rzzTlWsWFHVqlVTz549dfDgQac+Fy9e1IgRI1S5cmVVqFBBvXv3VkpKiosqBgAAgCuV6nD76aefasSIEfrqq6+0YcMGZWVlqX379jp//ryjz9ixY/W///1P7733nj799FOdPHlSvXr1cmHVAAAAcBV3VxdwLWvXrnV6vWTJElWrVk2JiYm6++67lZaWptdee03Lli3TPffcI0lavHixIiMj9dVXX+lvf/tbnvvNzMxUZmam43V6evrNOwkAAACUmFJ95/ZqaWlpkqSAgABJUmJiorKyshQTE+PoU7duXdWoUUMJCQn57mf69Ony8/NzLCEhITe3cAAAAJSIMhNuc3JyNGbMGLVs2VK33367JCk5OVmenp7y9/d36hsYGKjk5OR89zVhwgSlpaU5luPHj9/M0gEAAFBCSvW0hD8bMWKE9u7dq88///yG92W322W324uhKgAAAJQmZeLO7ciRI7VmzRpt2bJFt956q6M9KChIly5dUmpqqlP/lJQUBQUFlXCVAAAAcLVSHW6NMRo5cqRWrVqlzZs3Kzw83Gl906ZN5eHhoU2bNjnaDh48qGPHjik6OrqkywUAAICLleppCSNGjNCyZcv0wQcfqGLFio55tH5+fvL29pafn58GDRqkcePGKSAgQL6+vho1apSio6PzfVICAAAArKtUh9sFCxZIktq0aePUvnjxYj300EOSpNmzZ8vNzU29e/dWZmamOnTooPnz55dwpQAAACgNSnW4NcZct4+Xl5fi4+MVHx9fAhUBAACgNCvVc24BAACAwiDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAyyDcAgAAwDIItwAAALAMwi0AAAAsg3ALAAAAy7BMuI2Pj1dYWJi8vLwUFRWlr7/+2tUlAQAAoIRZIty+++67GjdunCZPnqxdu3apUaNG6tChg06dOuXq0gAAAFCCLBFuZ82apSFDhmjgwIGqV6+eFi5cqPLly+v11193dWkAAAAoQe6uLuBGXbp0SYmJiZowYYKjzc3NTTExMUpISMhzm8zMTGVmZjpep6WlSZLS09NvbrF/kpP5e4kdC4BrlOR7SmnDexxgfSX9HnfleMaYa/Yr8+H2t99+U3Z2tgIDA53aAwMDdeDAgTy3mT59uqZOnZqrPSQk5KbUCOCvyW+OqysAgJvHVe9x586dk5+fX77ry3y4LYoJEyZo3Lhxjtc5OTk6c+aMKleuLJvN5sLKSr/09HSFhITo+PHj8vX1dXU5ZQbjVjSMW9ExdkXDuBUN41Z0jF3BGWN07tw5BQcHX7NfmQ+3VapUUbly5ZSSkuLUnpKSoqCgoDy3sdvtstvtTm3+/v43q0RL8vX15Q9hETBuRcO4FR1jVzSMW9EwbkXH2BXMte7YXlHmP1Dm6emppk2batOmTY62nJwcbdq0SdHR0S6sDAAAACWtzN+5laRx48ZpwIABatasmZo3b645c+bo/PnzGjhwoKtLAwAAQAmyRLjt16+ffv31V02aNEnJyclq3Lix1q5dm+tDZrhxdrtdkydPzjWtA9fGuBUN41Z0jF3RMG5Fw7gVHWNX/Gzmes9TAAAAAMqIMj/nFgAAALiCcAsAAADLINwCAADAMgi3AAAAsAzCLZycOXNGcXFx8vX1lb+/vwYNGqSMjIxr9h81apTq1Kkjb29v1ahRQ6NHj1ZaWppTP5vNlmtZvnz5zT6dmyo+Pl5hYWHy8vJSVFSUvv7662v2f++991S3bl15eXmpQYMG+vjjj53WG2M0adIkVa9eXd7e3oqJidGhQ4du5im4RGHGbdGiRbrrrrtUqVIlVapUSTExMbn6P/TQQ7murY4dO97s0yhxhRm3JUuW5BoTLy8vpz5cb7m1adMmz/eqLl26OPr8Fa63bdu2qVu3bgoODpbNZtPq1auvu83WrVt1xx13yG63q3bt2lqyZEmuPoV9zyyLCjt2K1eu1L333quqVavK19dX0dHRWrdunVOfKVOm5Lrm6tatexPPouwj3MJJXFyc9u3bpw0bNmjNmjXatm2bhg4dmm//kydP6uTJk5o5c6b27t2rJUuWaO3atRo0aFCuvosXL9Yvv/ziWHr27HkTz+TmevfddzVu3DhNnjxZu3btUqNGjdShQwedOnUqz/5ffvml7r//fg0aNEi7d+9Wz5491bNnT+3du9fRZ8aMGZo7d64WLlyo7du3y8fHRx06dNDFixdL6rRuusKO29atW3X//fdry5YtSkhIUEhIiNq3b68TJ0449evYsaPTtfXOO++UxOmUmMKOm/THtx39eUyOHj3qtJ7rLbeVK1c6jdnevXtVrlw59enTx6mf1a+38+fPq1GjRoqPjy9Q/6SkJHXp0kVt27bVnj17NGbMGA0ePNgppBXlGi6LCjt227Zt07333quPP/5YiYmJatu2rbp166bdu3c79atfv77TNff555/fjPKtwwD/v++//95IMjt27HC0ffLJJ8Zms5kTJ04UeD8rVqwwnp6eJisry9Emyaxatao4y3Wp5s2bmxEjRjheZ2dnm+DgYDN9+vQ8+/ft29d06dLFqS0qKso8/PDDxhhjcnJyTFBQkHnhhRcc61NTU43dbjfvvPPOTTgD1yjsuF3t8uXLpmLFiuaNN95wtA0YMMD06NGjuEstVQo7bosXLzZ+fn757o/rrWDX2+zZs03FihVNRkaGo+2vcL39WUHeux977DFTv359p7Z+/fqZDh06OF7f6M+iLCrq33v16tUzU6dOdbyePHmyadSoUfEV9hfAnVs4JCQkyN/fX82aNXO0xcTEyM3NTdu3by/wftLS0uTr6yt3d+fvCBkxYoSqVKmi5s2b6/XXX5cpo49YvnTpkhITExUTE+Noc3NzU0xMjBISEvLcJiEhwam/JHXo0MHRPykpScnJyU59/Pz8FBUVle8+y5qijNvVfv/9d2VlZSkgIMCpfevWrapWrZrq1KmjYcOG6fTp08VauysVddwyMjIUGhqqkJAQ9ejRQ/v27XOs43or2Dm+9tprio2NlY+Pj1O7la+3orje+1tx/Cz+KnJycnTu3Llc73GHDh1ScHCwatasqbi4OB07dsxFFZYNhFs4JCcnq1q1ak5t7u7uCggIUHJycoH28dtvv+npp5/ONZVh2rRpWrFihTZs2KDevXtr+PDhmjdvXrHVXpJ+++03ZWdn5/oGvMDAwHzHKTk5+Zr9r/xamH2WNUUZt6s9/vjjCg4OdvpLsmPHjnrzzTe1adMmPf/88/r000/VqVMnZWdnF2v9rlKUcatTp45ef/11ffDBB3r77beVk5OjFi1a6Oeff5bE9VaQc/z666+1d+9eDR482Knd6tdbUeT3/paenq4LFy4Uy5/9v4qZM2cqIyNDffv2dbRFRUU5pvwtWLBASUlJuuuuu3Tu3DkXVlq6WeLrd3FtTzzxhJ5//vlr9tm/f/8NHyc9PV1dunRRvXr1NGXKFKd1EydOdPy+SZMmOn/+vF544QWNHj36ho+Lv4bnnntOy5cv19atW50+HBUbG+v4fYMGDdSwYUPVqlVLW7duVbt27VxRqstFR0crOjra8bpFixaKjIzUK6+8oqefftqFlZUdr732mho0aKDmzZs7tXO94WZZtmyZpk6dqg8++MDpRlOnTp0cv2/YsKGioqIUGhqqFStW5Pn5FnDn9i/h0Ucf1f79+6+51KxZU0FBQbkm91++fFlnzpxRUFDQNY9x7tw5dezYURUrVtSqVavk4eFxzf5RUVH6+eeflZmZecPnV9KqVKmicuXKKSUlxak9JSUl33EKCgq6Zv8rvxZmn2VNUcbtipkzZ+q5557T+vXr1bBhw2v2rVmzpqpUqaLDhw/fcM2lwY2M2xUeHh5q0qSJY0y43q59jufPn9fy5csLFBysdr0VRX7vb76+vvL29i6Wa9jqli9frsGDB2vFihW5pnhczd/fX7fddttf+pq7HsLtX0DVqlVVt27day6enp6Kjo5WamqqEhMTHdtu3rxZOTk5ioqKynf/6enpat++vTw9PfXhhx/meuRQXvbs2aNKlSrJbrcXyzmWJE9PTzVt2lSbNm1ytOXk5GjTpk1Od8v+LDo62qm/JG3YsMHRPzw8XEFBQU590tPTtX379nz3WdYUZdykPz7V//TTT2vt2rVO88Hz8/PPP+v06dOqXr16sdTtakUdtz/Lzs7Wd9995xgTrrdrn+N7772nzMxMPfDAA9c9jtWut6K43vtbcVzDVvbOO+9o4MCBeuedd5weO5efjIwM/fjjj3/pa+66XP2JNpQuHTt2NE2aNDHbt283n3/+uYmIiDD333+/Y/3PP/9s6tSpY7Zv326MMSYtLc1ERUWZBg0amMOHD5tffvnFsVy+fNkYY8yHH35oFi1aZL777jtz6NAhM3/+fFO+fHkzadIkl5xjcVi+fLmx2+1myZIl5vvvvzdDhw41/v7+Jjk52RhjTP/+/c0TTzzh6P/FF18Yd3d3M3PmTLN//34zefJk4+HhYb777jtHn+eee874+/ubDz74wHz77bemR48eJjw83Fy4cKHEz+9mKey4Pffcc8bT09O8//77TtfWuXPnjDHGnDt3zvzrX/8yCQkJJikpyWzcuNHccccdJiIiwly8eNEl53gzFHbcpk6datatW2d+/PFHk5iYaGJjY42Xl5fZt2+fow/XW+5xu6JVq1amX79+udr/KtfbuXPnzO7du83u3buNJDNr1iyze/duc/ToUWOMMU888YTp37+/o/9PP/1kypcvb8aPH2/2799v4uPjTbly5czatWsdfa73s7CKwo7d0qVLjbu7u4mPj3d6j0tNTXX0efTRR83WrVtNUlKS+eKLL0xMTIypUqWKOXXqVImfX1lBuIWT06dPm/vvv99UqFDB+Pr6moEDBzqChDHGJCUlGUlmy5YtxhhjtmzZYiTluSQlJRlj/nicWOPGjU2FChWMj4+PadSokVm4cKHJzs52wRkWn3nz5pkaNWoYT09P07x5c/PVV1851rVu3doMGDDAqf+KFSvMbbfdZjw9PU39+vXNRx995LQ+JyfHTJw40QQGBhq73W7atWtnDh48WBKnUqIKM26hoaF5XluTJ082xhjz+++/m/bt25uqVasaDw8PExoaaoYMGWK5vzCNKdy4jRkzxtE3MDDQdO7c2ezatctpf1xvef85PXDggJFk1q9fn2tff5XrLb/39StjNWDAANO6detc2zRu3Nh4enqamjVrmsWLF+fa77V+FlZR2LFr3br1Nfsb88dj1apXr248PT3NLbfcYvr162cOHz5csidWxtiMKaPPYwIAAACuwpxbAAAAWAbhFgAAAJZBuAUAAIBlEG4BAABgGYRbAAAAWAbhFgAAAJZBuAUAAIBlEG4BAABgGYRbALhJbDabVq9e7eoyimTKlClq3LjxDe3jyJEjstls2rNnT7HUBAAFQbgFgCJITk7WqFGjVLNmTdntdoWEhKhbt27atGmTq0uTJLVp00ZjxoxxdRkAUOLcXV0AAJQ1R44cUcuWLeXv768XXnhBDRo0UFZWltatW6cRI0bowIEDri4RAP6yuHMLAIU0fPhw2Ww2ff311+rdu7duu+021a9fX+PGjdNXX32V73aPP/64brvtNpUvX141a9bUxIkTlZWV5Vj/zTffqG3btqpYsaJ8fX3VtGlT7dy5U5J09OhRdevWTZUqVZKPj4/q16+vjz/+uMjncL1arnjllVcUEhKi8uXLq2/fvkpLS3Na/3//93+KjIyUl5eX6tatq/nz5+d7zLNnzyouLk5Vq1aVt7e3IiIitHjx4iKfAwDkhTu3AFAIZ86c0dq1a/XMM8/Ix8cn13p/f/98t61YsaKWLFmi4OBgfffddxoyZIgqVqyoxx57TJIUFxenJk2aaMGCBSpXrpz27NkjDw8PSdKIESN06dIlbdu2TT4+Pvr+++9VoUKFIp/H9WqRpMOHD2vFihX63//+p/T0dA0aNEjDhw/X0qVLJUlLly7VpEmT9PLLL6tJkybavXu3hgwZIh8fHw0YMCDXMSdOnKjvv/9en3zyiapUqaLDhw/rwoULRT4HAMgL4RYACuHw4cMyxqhu3bqF3vapp55y/D4sLEz/+te/tHz5ckegPHbsmMaPH+/Yd0REhKP/sWPH1Lt3bzVo0ECSVLNmzRs5jevWIkkXL17Um2++qVtuuUWSNG/ePHXp0kUvvviigoKCNHnyZL344ovq1auXJCk8PFzff/+9XnnllTzD7bFjx9SkSRM1a9bMcVwAKG6EWwAoBGNMkbd99913NXfuXP3444/KyMjQ5cuX5evr61g/btw4DR48WG+99ZZiYmLUp08f1apVS5I0evRoDRs2TOvXr1dMTIx69+6thg0b3rRaJKlGjRqOYCtJ0dHRysnJ0cGDB1WxYkX9+OOPGjRokIYMGeLoc/nyZfn5+eV5zGHDhql3797atWuX2rdvr549e6pFixZFPgcAyAtzbgGgECIiImSz2Qr9obGEhATFxcWpc+fOWrNmjXbv3q0nn3xSly5dcvSZMmWK9u3bpy5dumjz5s2qV6+eVq1aJUkaPHiwfvrpJ/Xv31/fffedmjVrpnnz5hXpHApSy/VkZGRIkhYtWqQ9e/Y4lr179+Y777hTp046evSoxo4dq5MnT6pdu3b617/+VaRzAID8EG4BoBACAgLUoUMHxcfH6/z587nWp6am5rndl19+qdDQUD355JNq1qyZIiIidPTo0Vz9brvtNo0dO1br169Xr169nD5wFRISon/+859auXKlHn30US1atKhI51DQWo4dO6aTJ086Xn/11Vdyc3NTnTp1FBgYqODgYP3000+qXbu20xIeHp7vsatWraoBAwbo7bff1pw5c/Tqq68W6RwAID9MSwCAQoqPj1fLli3VvHlzTZs2TQ0bNtTly5e1YcMGLViwQPv378+1TUREhI4dO6bly5frzjvv1EcffeS4KytJFy5c0Pjx43XfffcpPDxcP//8s3bs2KHevXtLksaMGaNOnTrptttu09mzZ7VlyxZFRkZes85ff/011xcoVK9e/bq1XOHl5aUBAwZo5syZSk9P1+jRo9W3b18FBQVJkqZOnarRo0fLz89PHTt2VGZmpnbu3KmzZ89q3LhxufY3adIkNW3aVPXr11dmZqbWrFlz3XMAgEIzAIBCO3nypBkxYoQJDQ01np6e5pZbbjHdu3c3W7ZscfSRZFatWuV4PX78eFO5cmVToUIF069fPzN79mzj5+dnjDEmMzPTxMbGmpCQEOPp6WmCg4PNyJEjzYULF4wxxowcOdLUqlXL2O12U7VqVdO/f3/z22+/5Vtf69atjaRcy9NPP33dWowxZvLkyaZRo0Zm/vz5Jjg42Hh5eZn77rvPnDlzxuk4S5cuNY0bNzaenp6mUqVK5u677zYrV640xhiTlJRkJJndu3cbY4x5+umnTWRkpPH29jYBAQGmR48e5qeffiriTwAA8mYz5gY+HQEAAACUIsy5BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYBuEWAAAAlkG4BQAAgGUQbgEAAGAZhFsAAABYxv8HoHCh0CSD6OcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_labels = sorted(y.unique())  # Get unique class labels\n",
    "\n",
    "# Count the occurrences of each class\n",
    "class_counts = y.value_counts()\n",
    "\n",
    "# Create a bar plot to visualize the class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(class_labels, class_counts)\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution of Target Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Why is accuracy low? why does the saga solver perform poorly?\n",
    " - Because the dataset is imbalanced. One class significantly outnumbers the other in the target variable, the model may have a bias towards the majority class.\n",
    " - The 'saga' solver is known for handling large datasets. It is not suitable for small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "[[ 1.5997544  -1.43222015 -0.15123497 -0.00401141]] [-0.07601213]\n"
     ]
    }
   ],
   "source": [
    "# Change the solver to \"liblinear\"\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train, y_train)\n",
    "# Predict on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(logreg.coef_, logreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is accuracy now? why does the \"liblinear\" solver perform better than \"saga\" solver ?\n",
    "- The 'liblinear' solver is a good choice for small to medium-sized datasets.\n",
    "- It's a reliable solver for binary and multiclass classification problems which have a moderate amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with saga solver: 0.9767441860465116\n",
      "[[ 3.90444435 -0.8235542   0.18542445 -0.73554556]] [-1.96733388]\n",
      "Accuracy with liblinear solver: 0.9767441860465116\n",
      "[[ 3.77819685 -0.75341497  0.17248526 -0.71597049]] [-1.72205563]\n"
     ]
    }
   ],
   "source": [
    "# Repeat the above tasks after feature normalization and observe the accuracy levels.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression(solver='saga')\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred_1 = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
    "print(\"Accuracy with saga solver:\", accuracy_1)\n",
    "\n",
    "print(logreg.coef_, logreg.intercept_)\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred_2 = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
    "print(\"Accuracy with liblinear solver:\", accuracy_2)\n",
    "\n",
    "print(logreg.coef_, logreg.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now observe the accuracies for both  \"liblinear\" solver and \"saga\" solver. Why accuracy of the \"saga\" solver is increased?\n",
    "- Standardizing (scaling) the features using 'StandardScaler' can help the saga solver converge more effectively and improve the model's performance.\n",
    "- Features with different scales can cause numerical instability, leading to slower convergence or suboptimal solutions. Feature scaling provides enhanced numerical stability and convergence properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following code to load the dataset again, and use logistic regression for the classification.\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
      "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
      "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
      "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
      "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
      "\n",
      "   body_mass_g     sex  class_encoded  \n",
      "0       3750.0    Male              0  \n",
      "1       3800.0  Female              0  \n",
      "2       3250.0  Female              0  \n",
      "4       3450.0  Female              0  \n",
      "5       3650.0    Male              0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0  Torgersen            39.1           18.7              181.0       3750.0   \n",
       "1  Torgersen            39.5           17.4              186.0       3800.0   \n",
       "2  Torgersen            40.3           18.0              195.0       3250.0   \n",
       "4  Torgersen            36.7           19.3              193.0       3450.0   \n",
       "5  Torgersen            39.3           20.6              190.0       3650.0   \n",
       "\n",
       "      sex  \n",
       "0    Male  \n",
       "1  Female  \n",
       "2  Female  \n",
       "4  Female  \n",
       "5    Male  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the penguins dataset\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Filter rows for 'Adelie' and 'Chinstrap' classes\n",
    "selected_classes = ['Adelie', 'Chinstrap']\n",
    "df_filtered = df[df['species'].isin(selected_classes)].copy()  # Make a copy to avoid the warning\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Encode the species column\n",
    "y_encoded = le.fit_transform(df_filtered['species'])\n",
    "df_filtered['class_encoded'] = y_encoded\n",
    "\n",
    "\n",
    "print(df_filtered.head())\n",
    "\n",
    "X = df_filtered.drop(['species', 'class_encoded'], axis=1)  # Choose features\n",
    "y = df_filtered['class_encoded']  # Target variable\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Dream'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12116\\63413540.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlogreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'saga'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# logreg = LogisticRegression(max_iter=166, solver='newton-cg')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# logreg = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=100, multi_class='ovr', random_state=42)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Predict on the testing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 )\n\u001b[0;32m   1150\u001b[0m             ):\n\u001b[1;32m-> 1151\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1203\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    617\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m         raise ValueError(\n\u001b[0;32m   1144\u001b[0m             \u001b[1;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         )\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1148\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    914\u001b[0m                         )\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m                 raise ValueError(\n\u001b[0;32m    920\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         if (\n\u001b[0;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2001\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Dream'"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "logreg = LogisticRegression(solver='saga')\n",
    "# logreg = LogisticRegression(max_iter=166, solver='newton-cg')\n",
    "# logreg = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=100, multi_class='ovr', random_state=42)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(logreg.coef_, logreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the problem? Why algorithm cannot perform classification?\n",
    "- The error message \"ValueError: could not convert string to float: 'Dream'\" suggests that the logistic regression model encountered an issue because it cannot directly work with categorical or string data. In dataset, it seems there might be a categorical or non-numeric feature (possibly 'island' and 'sex') that the algorithm cannot use for classification without appropriate preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to solve this issue?\n",
    "- Need to encode the categorical features into numerical values using 'LabelEncoder' or 'OneHotEncoder' from the 'sklearn.preprocessing' module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>class_encoded</th>\n",
       "      <th>island_Dream</th>\n",
       "      <th>island_Torgersen</th>\n",
       "      <th>sex_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0  Adelie            39.1           18.7              181.0       3750.0   \n",
       "1  Adelie            39.5           17.4              186.0       3800.0   \n",
       "2  Adelie            40.3           18.0              195.0       3250.0   \n",
       "4  Adelie            36.7           19.3              193.0       3450.0   \n",
       "5  Adelie            39.3           20.6              190.0       3650.0   \n",
       "\n",
       "   class_encoded  island_Dream  island_Torgersen  sex_Male  \n",
       "0              0         False              True      True  \n",
       "1              0         False              True     False  \n",
       "2              0         False              True     False  \n",
       "4              0         False              True     False  \n",
       "5              0         False              True      True  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the following code, to replace string features with numerical ones.\n",
    "df_filtered = pd.get_dummies(df_filtered, columns=['island', 'sex'], drop_first=True)\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
      "0  Adelie            39.1           18.7              181.0       3750.0   \n",
      "1  Adelie            39.5           17.4              186.0       3800.0   \n",
      "\n",
      "   class_encoded  island_Dream  island_Torgersen  sex_Male  \n",
      "0              0         False              True      True  \n",
      "1              0         False              True     False  \n",
      "   species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
      "0   Adelie            39.1           18.7              181.0       3750.0   \n",
      "20  Adelie            37.8           18.3              174.0       3400.0   \n",
      "\n",
      "    class_encoded  island_Dream  island_Torgersen  sex_Male  \n",
      "0               0         False              True      True  \n",
      "20              0         False             False     False  \n",
      "   species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\n",
      "0   Adelie            39.1           18.7              181.0       3750.0   \n",
      "30  Adelie            39.5           16.7              178.0       3250.0   \n",
      "\n",
      "    class_encoded  island_Dream  island_Torgersen  sex_Male  \n",
      "0               0         False              True      True  \n",
      "30              0          True             False     False  \n"
     ]
    }
   ],
   "source": [
    "# Use the following code to visualize the encoding\n",
    "samples = df_filtered.groupby('sex_Male').head(1)\n",
    "print(samples)\n",
    "samples = df_filtered.groupby('island_Torgersen').head(1)\n",
    "print(samples)\n",
    "samples = df_filtered.groupby('island_Dream').head(1)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 7) (214,)\n",
      "Accuracy: 1.0\n",
      "[[ 3.63408911  0.16296484  0.62612347  0.10206609  2.59920768 -0.87721649\n",
      "  -0.35906787]] [-5.99579725]\n"
     ]
    }
   ],
   "source": [
    "# Use the following code to apply logistic regression\n",
    "X = df_filtered.drop(['species','class_encoded'], axis=1)\n",
    "\n",
    "y = df_filtered['class_encoded']  # Target variable\n",
    "print(X.shape, y.shape)\n",
    "X.head()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler=MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "logreg = LogisticRegression(solver='saga',max_iter=150,)\n",
    "\n",
    "#logreg = LogisticRegression(max_iter=166, solver='newton-cg')\n",
    "# logreg = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs', max_iter=100, multi_class='ovr', random_state=42)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(logreg.coef_, logreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why we are using the \"MaxAbsScaler\" scaler rather than the \"StandardScaler\"?\n",
    "- Because the 'MaxAbsScaler' is suitable for data that is already centered at zero or sparse data. It is meant for data that is already centered at zero or sparse data. It does not shift/center the data, and thus does not destroy any sparsity.\n",
    "- MaxAbsScaler is chosen over StandardScaler for binary features like \"island_Dream,\" \"island_Torgersen,\" and \"sex_Male\" to maintain their binary nature and only scale them within the [0, 1] range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59655172 0.98139535 0.93396226 0.91666667 0.         1.\n",
      "  1.        ]\n",
      " [0.8862069  0.88372093 0.94811321 0.82291667 1.         0.\n",
      "  1.        ]\n",
      " [0.68275862 0.8        0.9245283  0.73958333 0.         1.\n",
      "  0.        ]\n",
      " [0.87586207 0.86046512 0.94811321 0.92708333 1.         0.\n",
      "  1.        ]\n",
      " [0.7137931  0.86046512 0.95283019 0.80729167 0.         1.\n",
      "  1.        ]\n",
      " [0.64310345 0.95348837 0.93867925 0.78645833 0.         1.\n",
      "  1.        ]\n",
      " [0.65172414 0.85116279 0.82075472 0.70833333 0.         0.\n",
      "  0.        ]\n",
      " [0.5862069  0.79534884 0.87264151 0.70833333 1.         0.\n",
      "  0.        ]\n",
      " [0.73965517 0.81860465 0.9245283  0.97916667 0.         1.\n",
      "  1.        ]\n",
      " [0.62068966 0.79534884 0.88207547 0.77083333 1.         0.\n",
      "  0.        ]\n",
      " [0.82068966 0.85116279 0.91981132 0.80208333 1.         0.\n",
      "  0.        ]\n",
      " [0.80517241 0.83255814 0.91981132 0.6875     1.         0.\n",
      "  0.        ]\n",
      " [0.63103448 0.85581395 0.86792453 0.72395833 1.         0.\n",
      "  0.        ]\n",
      " [0.72586207 0.88837209 0.91981132 0.83333333 0.         1.\n",
      "  1.        ]\n",
      " [0.73275862 0.77674419 0.88207547 0.69791667 1.         0.\n",
      "  0.        ]\n",
      " [0.8362069  0.81395349 0.9009434  0.70833333 1.         0.\n",
      "  1.        ]\n",
      " [0.87758621 0.83255814 0.9245283  0.765625   1.         0.\n",
      "  0.        ]\n",
      " [0.65862069 0.84186047 0.87264151 0.82291667 0.         0.\n",
      "  1.        ]\n",
      " [0.69137931 0.87906977 0.88679245 0.89583333 0.         0.\n",
      "  1.        ]\n",
      " [0.80862069 0.77209302 0.90566038 0.5625     1.         0.\n",
      "  0.        ]\n",
      " [0.65344828 0.86511628 0.91037736 0.609375   0.         0.\n",
      "  0.        ]\n",
      " [0.96206897 0.92093023 0.97641509 0.83333333 1.         0.\n",
      "  1.        ]\n",
      " [0.85517241 0.84651163 0.91037736 0.78645833 1.         0.\n",
      "  1.        ]\n",
      " [0.85862069 0.80465116 0.93396226 0.765625   1.         0.\n",
      "  0.        ]\n",
      " [0.88448276 0.89302326 0.91037736 0.76041667 1.         0.\n",
      "  1.        ]\n",
      " [0.65689655 0.76744186 0.93396226 0.796875   0.         0.\n",
      "  0.        ]\n",
      " [0.67586207 0.98139535 0.9245283  0.86458333 1.         0.\n",
      "  1.        ]\n",
      " [0.68103448 0.77674419 0.83962264 0.67708333 1.         0.\n",
      "  0.        ]\n",
      " [0.91034483 0.93023256 0.96698113 0.94791667 1.         0.\n",
      "  1.        ]\n",
      " [0.65       0.86976744 0.8490566  0.75       0.         0.\n",
      "  1.        ]\n",
      " [0.71206897 0.98139535 0.91981132 0.91666667 0.         0.\n",
      "  1.        ]\n",
      " [0.64310345 0.78139535 0.90566038 0.625      1.         0.\n",
      "  0.        ]\n",
      " [0.81034483 0.80465116 0.87264151 0.77083333 1.         0.\n",
      "  0.        ]\n",
      " [0.74482759 0.86046512 0.90566038 0.85416667 1.         0.\n",
      "  1.        ]\n",
      " [0.73793103 0.86046512 0.91981132 0.88541667 0.         1.\n",
      "  1.        ]\n",
      " [0.85       0.9255814  0.95754717 0.84375    1.         0.\n",
      "  1.        ]\n",
      " [0.89655172 0.88372093 0.92924528 0.86458333 1.         0.\n",
      "  1.        ]\n",
      " [0.79482759 0.84651163 0.83962264 0.67708333 1.         0.\n",
      "  0.        ]\n",
      " [0.65172414 0.93023256 0.89622642 0.88541667 0.         0.\n",
      "  1.        ]\n",
      " [0.61551724 0.8372093  0.95283019 0.73958333 1.         0.\n",
      "  0.        ]\n",
      " [0.65862069 0.93023256 0.89622642 0.8125     0.         0.\n",
      "  1.        ]\n",
      " [0.73275862 0.80465116 0.88207547 0.69791667 1.         0.\n",
      "  0.        ]\n",
      " [0.61206897 0.75348837 0.91981132 0.69791667 0.         0.\n",
      "  0.        ]]\n",
      "[[-1.34082659  2.35505035  0.88068888  1.62029553 -1.14490646  1.80969611\n",
      "   1.01770049]\n",
      " [ 1.80078227  0.5480021   1.30057122  0.57562238  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [-0.40582395 -1.0008964   0.60076732 -0.35297599 -1.14490646  1.80969611\n",
      "  -0.98260737]\n",
      " [ 1.68858195  0.11775252  1.30057122  1.73637033  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [-0.069223    0.11775252  1.440532    0.40151018 -1.14490646  1.80969611\n",
      "   1.01770049]\n",
      " [-0.83592516  1.83875085  1.02064966  0.16936059 -1.14490646  1.80969611\n",
      "   1.01770049]\n",
      " [-0.7424249  -0.05434732 -2.47836983 -0.70120037 -1.14490646 -0.55257896\n",
      "  -0.98260737]\n",
      " [-1.4530269  -1.08694632 -0.93880125 -0.70120037  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 0.21127779 -0.65669673  0.60076732  2.3167443  -1.14490646  1.80969611\n",
      "   1.01770049]\n",
      " [-1.07902585 -1.08694632 -0.65887969 -0.0047516   0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 1.09018027 -0.05434732  0.46080654  0.34347279  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 0.92187979 -0.39854698  0.46080654 -0.93334996  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [-0.96682553  0.0317026  -1.07876203 -0.52708818  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 0.06167737  0.63405202  0.46080654  0.69169717 -1.14490646  1.80969611\n",
      "   1.01770049]\n",
      " [ 0.13647758 -1.43114598 -0.65887969 -0.81727517  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 1.25848074 -0.74274665 -0.09903657 -0.70120037  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [ 1.70728201 -0.39854698  0.60076732 -0.062789    0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [-0.66762469 -0.22644715 -0.93880125  0.57562238 -1.14490646 -0.55257896\n",
      "   1.01770049]\n",
      " [-0.31232369  0.46195218 -0.51891891  1.38814594 -1.14490646 -0.55257896\n",
      "   1.01770049]\n",
      " [ 0.9592799  -1.5171959   0.0409242  -2.3262475   0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [-0.72372485  0.20380243  0.18088498 -1.80391093 -1.14490646 -0.55257896\n",
      "  -0.98260737]\n",
      " [ 2.62358459  1.23640143  2.1403359   0.69169717  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [ 1.46418132 -0.14039723  0.18088498  0.16936059  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [ 1.50158143 -0.91484648  0.88068888 -0.062789    0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 1.78208222  0.72010193  0.18088498 -0.1208264   0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [-0.68632474 -1.60324582  0.88068888  0.28543539 -1.14490646 -0.55257896\n",
      "  -0.98260737]\n",
      " [-0.48062416  2.35505035  0.60076732  1.03992156  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [-0.424524   -1.43114598 -1.91852671 -1.04942476  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 2.06258301  1.40850127  1.86041434  1.96851992  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [-0.76112495  0.28985235 -1.63860515 -0.23690119 -1.14490646 -0.55257896\n",
      "   1.01770049]\n",
      " [-0.08792305  2.35505035  0.46080654  1.62029553 -1.14490646 -0.55257896\n",
      "   1.01770049]\n",
      " [-0.83592516 -1.34509607  0.0409242  -1.62979873  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 0.97797995 -0.91484648 -0.93880125 -0.0047516   0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [ 0.26737795  0.11775252  0.0409242   0.92384676  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [ 0.19257774  0.11775252  0.46080654  1.27207115 -1.14490646  1.80969611\n",
      "   1.01770049]\n",
      " [ 1.40808116  1.32245135  1.58049278  0.80777197  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [ 1.91298259  0.5480021   0.7407281   1.03992156  0.8734338  -0.55257896\n",
      "   1.01770049]\n",
      " [ 0.80967948 -0.14039723 -1.91852671 -1.04942476  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [-0.7424249   1.40850127 -0.23899735  1.27207115 -1.14490646 -0.55257896\n",
      "   1.01770049]\n",
      " [-1.13512601 -0.31249707  1.440532   -0.35297599  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [-0.66762469  1.40850127 -0.23899735  0.45954758 -1.14490646 -0.55257896\n",
      "   1.01770049]\n",
      " [ 0.13647758 -0.91484648 -0.65887969 -0.81727517  0.8734338  -0.55257896\n",
      "  -0.98260737]\n",
      " [-1.17252611 -1.86139557  0.46080654 -0.81727517 -1.14490646 -0.55257896\n",
      "  -0.98260737]]\n"
     ]
    }
   ],
   "source": [
    "# Use the following code to visualize feature scaling before and after normalization.\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "scaler=MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(X_test_scaled)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you observe in the values related to \"island_Dream\",    \"island_Torgersen\"  and   \"sex_Male\" features before and after scaling?\n",
    "- For binary features like \"island_Dream,\" \"island_Torgersen,\" and \"sex_Male,\" MaxAbsScaler will scale the values to be within the range [0, 1] since they are already binary (0 or 1). After scaling, these binary features will retain their 0 or 1 values because the maximum absolute value for these features is 1. So, there may not be a noticeable difference in these features before and after scaling when using MaxAbsScaler.\n",
    "- StandardScaler to binary features like \"island_Dream,\" \"island_Torgersen,\" and \"sex_Male,\" they may become centered around 0, which means they could have values around -0.5 and 0.5 instead of 0 and 1. This transformation might not be suitable for binary features because it can disrupt their original interpretation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
