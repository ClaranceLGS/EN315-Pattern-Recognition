{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic regression weight update process</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "centers = [[-5, 0], [0, 1.5]]\n",
    "X, y = make_blobs(n_samples=1000, centers=centers, random_state=40)\n",
    "transformation = [[0.4, 0.2], [-0.4, 1.2]]\n",
    "X = np.dot(X, transformation)\n",
    "# Add a bias term to the feature matrix\n",
    "X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "# Initialize coefficients\n",
    "W = np.zeros(X.shape[1])\n",
    "# Define the logistic sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "# Define the logistic loss ( binary cross - entropy ) function\n",
    "def log_loss(y_true, y_pred):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1-epsilon) # Clip to avoid log (0)\n",
    "    return -(y_true * np.log(y_pred) + (1 - y_true) * np.log (1 - y_pred ))\n",
    "# Gradient descent and Newton method parameters\n",
    "learning_rate = 0.1\n",
    "iterations = 10\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Gradient Descent\n",
    "for _ in range(iterations):\n",
    "    # Computing the predicted probabilities using the sigmoid function\n",
    "    y_pred = sigmoid(np.dot(X, W))\n",
    "    \n",
    "    # Computing the gradient of the loss function\n",
    "    gradient = (1 / len(y)) * np.dot(X.T, (y_pred - y))\n",
    "    \n",
    "    # Updating the weights using the gradient\n",
    "    W -= learning_rate * gradient\n",
    "    \n",
    "    # Calculating the loss and append it to the loss history\n",
    "    loss = np.mean(log_loss(y, y_pred))\n",
    "    loss_history.append(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Perform grid search for hyperparameter tuning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:67: RuntimeWarning: Invalid cache, redownloading file\n",
      "  warn(\"Invalid cache, redownloading file\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:592\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 592\u001b[0m value\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_safe_read(chunk_left))\n\u001b[0;32m    593\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:633\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m amt:\n\u001b[1;32m--> 633\u001b[0m     \u001b[39mraise\u001b[39;00m IncompleteRead(data, amt\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(data))\n\u001b[0;32m    634\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(49357 bytes read, 13008 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:59\u001b[0m, in \u001b[0;36m_retry_with_clean_cache.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m URLError:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:504\u001b[0m, in \u001b[0;36m_load_arff_response\u001b[1;34m(url, data_home, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, md5_checksum, n_retries, delay, read_csv_kwargs)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load the ARFF data associated with the OpenML URL.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \n\u001b[0;32m    437\u001b[0m \u001b[39mIn addition of loading the data, this function will also check the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39m    `output_array_type == \"pandas\"`.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m gzip_file \u001b[39m=\u001b[39m _open_openml_url(url, data_home, n_retries\u001b[39m=\u001b[39;49mn_retries, delay\u001b[39m=\u001b[39;49mdelay)\n\u001b[0;32m    505\u001b[0m \u001b[39mwith\u001b[39;00m closing(gzip_file):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:175\u001b[0m, in \u001b[0;36m_open_openml_url\u001b[1;34m(openml_path, data_home, n_retries, delay)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[39mwith\u001b[39;00m opener(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tmpdir, file_name), \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[1;32m--> 175\u001b[0m         shutil\u001b[39m.\u001b[39;49mcopyfileobj(fsrc, fdst)\n\u001b[0;32m    176\u001b[0m shutil\u001b[39m.\u001b[39mmove(fdst\u001b[39m.\u001b[39mname, local_path)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\shutil.py:197\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m     buf \u001b[39m=\u001b[39m fsrc_read(length)\n\u001b[0;32m    198\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:460\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked:\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_chunked(amt)\n\u001b[0;32m    462\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:598\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    597\u001b[0m \u001b[39mexcept\u001b[39;00m IncompleteRead \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m--> 598\u001b[0m     \u001b[39mraise\u001b[39;00m IncompleteRead(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(value)) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(959372 bytes read)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Pattern Recognition\\EN3150-Pattern-Recognition\\Assignment 2\\EN3150_200094R_A02.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Pattern%20Recognition/EN3150-Pattern-Recognition/Assignment%202/EN3150_200094R_A02.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# data loading\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Pattern%20Recognition/EN3150-Pattern-Recognition/Assignment%202/EN3150_200094R_A02.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m train_samples \u001b[39m=\u001b[39m \u001b[39m500\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Pattern%20Recognition/EN3150-Pattern-Recognition/Assignment%202/EN3150_200094R_A02.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m X, y \u001b[39m=\u001b[39m fetch_openml(\u001b[39m'\u001b[39;49m\u001b[39mmnist_784\u001b[39;49m\u001b[39m'\u001b[39;49m, version\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, return_X_y\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, as_frame\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Pattern%20Recognition/EN3150-Pattern-Recognition/Assignment%202/EN3150_200094R_A02.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Pattern%20Recognition/EN3150-Pattern-Recognition/Assignment%202/EN3150_200094R_A02.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m permutation \u001b[39m=\u001b[39m random_state\u001b[39m.\u001b[39mpermutation(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1118\u001b[0m, in \u001b[0;36mfetch_openml\u001b[1;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[39m# obtain the data\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m url \u001b[39m=\u001b[39m _DATA_FILE\u001b[39m.\u001b[39mformat(data_description[\u001b[39m\"\u001b[39m\u001b[39mfile_id\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m-> 1118\u001b[0m bunch \u001b[39m=\u001b[39m _download_data_to_bunch(\n\u001b[0;32m   1119\u001b[0m     url,\n\u001b[0;32m   1120\u001b[0m     return_sparse,\n\u001b[0;32m   1121\u001b[0m     data_home,\n\u001b[0;32m   1122\u001b[0m     as_frame\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m(as_frame),\n\u001b[0;32m   1123\u001b[0m     openml_columns_info\u001b[39m=\u001b[39;49mfeatures_list,\n\u001b[0;32m   1124\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m   1125\u001b[0m     target_columns\u001b[39m=\u001b[39;49mtarget_columns,\n\u001b[0;32m   1126\u001b[0m     data_columns\u001b[39m=\u001b[39;49mdata_columns,\n\u001b[0;32m   1127\u001b[0m     md5_checksum\u001b[39m=\u001b[39;49mdata_description[\u001b[39m\"\u001b[39;49m\u001b[39mmd5_checksum\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1128\u001b[0m     n_retries\u001b[39m=\u001b[39;49mn_retries,\n\u001b[0;32m   1129\u001b[0m     delay\u001b[39m=\u001b[39;49mdelay,\n\u001b[0;32m   1130\u001b[0m     parser\u001b[39m=\u001b[39;49mparser_,\n\u001b[0;32m   1131\u001b[0m     read_csv_kwargs\u001b[39m=\u001b[39;49mread_csv_kwargs,\n\u001b[0;32m   1132\u001b[0m )\n\u001b[0;32m   1134\u001b[0m \u001b[39mif\u001b[39;00m return_X_y:\n\u001b[0;32m   1135\u001b[0m     \u001b[39mreturn\u001b[39;00m bunch\u001b[39m.\u001b[39mdata, bunch\u001b[39m.\u001b[39mtarget\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:669\u001b[0m, in \u001b[0;36m_download_data_to_bunch\u001b[1;34m(url, sparse, data_home, as_frame, openml_columns_info, data_columns, target_columns, shape, md5_checksum, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m ParserError\n\u001b[0;32m    667\u001b[0m     no_retry_exception \u001b[39m=\u001b[39m ParserError\n\u001b[1;32m--> 669\u001b[0m X, y, frame, categories \u001b[39m=\u001b[39m _retry_with_clean_cache(\n\u001b[0;32m    670\u001b[0m     url, data_home, no_retry_exception\n\u001b[0;32m    671\u001b[0m )(_load_arff_response)(\n\u001b[0;32m    672\u001b[0m     url,\n\u001b[0;32m    673\u001b[0m     data_home,\n\u001b[0;32m    674\u001b[0m     parser\u001b[39m=\u001b[39;49mparser,\n\u001b[0;32m    675\u001b[0m     output_type\u001b[39m=\u001b[39;49moutput_type,\n\u001b[0;32m    676\u001b[0m     openml_columns_info\u001b[39m=\u001b[39;49mfeatures_dict,\n\u001b[0;32m    677\u001b[0m     feature_names_to_select\u001b[39m=\u001b[39;49mdata_columns,\n\u001b[0;32m    678\u001b[0m     target_names_to_select\u001b[39m=\u001b[39;49mtarget_columns,\n\u001b[0;32m    679\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[0;32m    680\u001b[0m     md5_checksum\u001b[39m=\u001b[39;49mmd5_checksum,\n\u001b[0;32m    681\u001b[0m     n_retries\u001b[39m=\u001b[39;49mn_retries,\n\u001b[0;32m    682\u001b[0m     delay\u001b[39m=\u001b[39;49mdelay,\n\u001b[0;32m    683\u001b[0m     read_csv_kwargs\u001b[39m=\u001b[39;49mread_csv_kwargs,\n\u001b[0;32m    684\u001b[0m )\n\u001b[0;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m Bunch(\n\u001b[0;32m    687\u001b[0m     data\u001b[39m=\u001b[39mX,\n\u001b[0;32m    688\u001b[0m     target\u001b[39m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m     target_names\u001b[39m=\u001b[39mtarget_columns,\n\u001b[0;32m    693\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:71\u001b[0m, in \u001b[0;36m_retry_with_clean_cache.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(local_path):\n\u001b[0;32m     70\u001b[0m     os\u001b[39m.\u001b[39munlink(local_path)\n\u001b[1;32m---> 71\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:504\u001b[0m, in \u001b[0;36m_load_arff_response\u001b[1;34m(url, data_home, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, md5_checksum, n_retries, delay, read_csv_kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_arff_response\u001b[39m(\n\u001b[0;32m    422\u001b[0m     url: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    423\u001b[0m     data_home: Optional[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    433\u001b[0m     read_csv_kwargs: Optional[Dict] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    434\u001b[0m ):\n\u001b[0;32m    435\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load the ARFF data associated with the OpenML URL.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \n\u001b[0;32m    437\u001b[0m \u001b[39m    In addition of loading the data, this function will also check the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39m        `output_array_type == \"pandas\"`.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     gzip_file \u001b[39m=\u001b[39m _open_openml_url(url, data_home, n_retries\u001b[39m=\u001b[39;49mn_retries, delay\u001b[39m=\u001b[39;49mdelay)\n\u001b[0;32m    505\u001b[0m     \u001b[39mwith\u001b[39;00m closing(gzip_file):\n\u001b[0;32m    506\u001b[0m         md5 \u001b[39m=\u001b[39m hashlib\u001b[39m.\u001b[39mmd5()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:175\u001b[0m, in \u001b[0;36m_open_openml_url\u001b[1;34m(openml_path, data_home, n_retries, delay)\u001b[0m\n\u001b[0;32m    173\u001b[0m                 opener \u001b[39m=\u001b[39m gzip\u001b[39m.\u001b[39mGzipFile\n\u001b[0;32m    174\u001b[0m             \u001b[39mwith\u001b[39;00m opener(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(tmpdir, file_name), \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fdst:\n\u001b[1;32m--> 175\u001b[0m                 shutil\u001b[39m.\u001b[39;49mcopyfileobj(fsrc, fdst)\n\u001b[0;32m    176\u001b[0m         shutil\u001b[39m.\u001b[39mmove(fdst\u001b[39m.\u001b[39mname, local_path)\n\u001b[0;32m    177\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\shutil.py:197\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    195\u001b[0m fdst_write \u001b[39m=\u001b[39m fdst\u001b[39m.\u001b[39mwrite\n\u001b[0;32m    196\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m     buf \u001b[39m=\u001b[39m fsrc_read(length)\n\u001b[0;32m    198\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buf:\n\u001b[0;32m    199\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:460\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunked:\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_chunked(amt)\n\u001b[0;32m    462\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[0;32m    464\u001b[0m         \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:592\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_left \u001b[39m=\u001b[39m chunk_left \u001b[39m-\u001b[39m amt\n\u001b[0;32m    590\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 592\u001b[0m value\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_safe_read(chunk_left))\n\u001b[0;32m    593\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    594\u001b[0m     amt \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m chunk_left\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:631\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_read\u001b[39m(\u001b[39mself\u001b[39m, amt):\n\u001b[0;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[39m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[39m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[0;32m    630\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mread(amt)\n\u001b[0;32m    632\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m<\u001b[39m amt:\n\u001b[0;32m    633\u001b[0m         \u001b[39mraise\u001b[39;00m IncompleteRead(data, amt\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import check_random_state\n",
    "# data loading\n",
    "train_samples = 500\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "random_state = check_random_state(0)\n",
    "permutation = random_state.permutation(X.shape[0])\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_samples, test_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
